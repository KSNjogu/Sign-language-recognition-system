{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb9e663-4e51-4fbb-9f4e-f40db3e9441c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dfd7f8-ec4c-4f77-a67a-cab11a7f1c12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(max_num_hands=1)  # Only detect ONE hand\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Create dataset directory\n",
    "dataset_path = \"KENYA_SIGN_LANGUAGE/alphabet_dataset\"\n",
    "os.makedirs(dataset_path, exist_ok=True)\n",
    "\n",
    "# Define letters (A-z)\n",
    "letters = [chr(c) for c in range(ord('A'), ord('Z') + 1)]\n",
    "#print(letters)\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam\")\n",
    "    exit()\n",
    "\n",
    "cv2.namedWindow(\"KSL Data Collector\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"KSL Data Collector\", 800, 600)\n",
    "\n",
    "for letter in letters:\n",
    "    letter_path = os.path.join(dataset_path, letter)\n",
    "    os.makedirs(letter_path, exist_ok=True)\n",
    "    \n",
    "    print(f\"\\nCollecting images for letter: {letter}\")\n",
    "    print(\"Press:\")\n",
    "    print(\"  's' - Save when hand is properly boxed\")\n",
    "    print(\"  'q' - Finish this letter\")\n",
    "    \n",
    "    count = len(os.listdir(letter_path))\n",
    "    target_images = 30  # Adjust as needed\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error reading frame\")\n",
    "            break\n",
    "            \n",
    "        # Flip frame for mirror effect\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        \n",
    "        # Convert to RGB for MediaPipe\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(rgb_frame)\n",
    "        \n",
    "        # Clear instructions\n",
    "        instruction = f\"Show ONE hand for: {letter} ({count}/{target_images})\"\n",
    "        cv2.putText(frame, instruction, (10, 30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "        \n",
    "        # Hand detection and boxing\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                # Draw landmarks (optional)\n",
    "                mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                \n",
    "                # Get hand bounding box\n",
    "                h, w, _ = frame.shape\n",
    "                x_max = y_max = 0\n",
    "                x_min, y_min = w, h\n",
    "                \n",
    "                for lm in hand_landmarks.landmark:\n",
    "                    x, y = int(lm.x * w), int(lm.y * h)\n",
    "                    if x > x_max: x_max = x\n",
    "                    if x < x_min: x_min = x\n",
    "                    if y > y_max: y_max = y\n",
    "                    if y < y_min: y_min = y\n",
    "                \n",
    "                # Add padding and draw box\n",
    "                padding = 20\n",
    "                x_min = max(0, x_min - padding)\n",
    "                y_min = max(0, y_min - padding)\n",
    "                x_max = min(w, x_max + padding)\n",
    "                y_max = min(h, y_max + padding)\n",
    "                \n",
    "                cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0,255,0), 2)\n",
    "                \n",
    "                # Display \"READY\" when hand is detected\n",
    "                cv2.putText(frame, \"READY TO CAPTURE\", (x_min, y_min-10),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,255), 2)\n",
    "        \n",
    "        cv2.imshow(\"KSL Data Collector\", frame)\n",
    "        \n",
    "        key = cv2.waitKey(1)\n",
    "        \n",
    "        if key == ord('s') and results.multi_hand_landmarks:\n",
    "            # Crop and save only the boxed hand region\n",
    "            hand_crop = frame[y_min:y_max, x_min:x_max]\n",
    "            if hand_crop.size != 0:\n",
    "                img_path = os.path.join(letter_path, f\"{letter}_{count}.jpg\")\n",
    "                cv2.imwrite(img_path, hand_crop)\n",
    "                print(f\"Saved: {img_path}\")\n",
    "                count += 1\n",
    "                \n",
    "                # Show confirmation\n",
    "                frame[y_min:y_max, x_min:x_max] = cv2.blur(frame[y_min:y_max, x_min:x_max], (30,30))\n",
    "                cv2.putText(frame, \"SAVED!\", (w//2-100, h//2), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 2, (0,255,0), 3)\n",
    "                cv2.imshow(\"KSL Data Collector\", frame)\n",
    "                cv2.waitKey(300)\n",
    "                \n",
    "                if count >= target_images:\n",
    "                    break\n",
    "                    \n",
    "        elif key == ord('q'):\n",
    "            break\n",
    "        elif key == 27:  # ESC\n",
    "            hands.close()\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            exit()\n",
    "\n",
    "print(\"\\nData collection complete!\")\n",
    "hands.close()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65930756-0ac3-4bff-bda4-ade6904b3a0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Config\n",
    "dataset_path = \"KENYA_SIGN_LANGUAGE/alphabet_dataset\"  # Updated path\n",
    "img_size = 256\n",
    "test_ratio = 0.1\n",
    "val_ratio = 0.2\n",
    "\n",
    "# Aâ€“Z letters\n",
    "letters = [chr(c) for c in range(ord('A'), ord('Z') + 1)]\n",
    "letter_to_label = {letter: idx for idx, letter in enumerate(letters)}\n",
    "\n",
    "# Load and preprocess images\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "print(\"Loading and preprocessing images...\")\n",
    "\n",
    "for letter in letters:\n",
    "    letter_folder = os.path.join(dataset_path, letter)\n",
    "    if not os.path.exists(letter_folder):\n",
    "        print(f\"Warning: Folder {letter_folder} not found. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    for img_name in os.listdir(letter_folder):\n",
    "        img_path = os.path.join(letter_folder, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        if img is None:\n",
    "            continue  # Skip unreadable files\n",
    "\n",
    "        img = cv2.resize(img, (img_size, img_size))\n",
    "        img = img / 255.0  # Normalize\n",
    "        X.append(img)\n",
    "        y.append(letter_to_label[letter])\n",
    "\n",
    "X = np.array(X, dtype=np.float32)\n",
    "y = np.array(y)\n",
    "\n",
    "print(f\"Total samples loaded: {len(X)}\")\n",
    "\n",
    "# Split into train, validation, and test sets\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=test_ratio, stratify=y, random_state=42)\n",
    "val_size = val_ratio / (1 - test_ratio)  # Adjust val ratio from remaining\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=val_size, stratify=y_temp, random_state=42)\n",
    "\n",
    "print(f\"Split sizes => Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
    "\n",
    "# Save to .npz files\n",
    "np.savez_compressed(\"KENYA_SIGN_LANGUAGE/ksl_alphabet_train.npz\", X=X_train, y=y_train)\n",
    "np.savez_compressed(\"KENYA_SIGN_LANGUAGE/ksl_alphabet_val.npz\", X=X_val, y=y_val)\n",
    "np.savez_compressed(\"KENYA_SIGN_LANGUAGE/ksl_alphabet_test.npz\", X=X_test, y=y_test)\n",
    "\n",
    "print(\"Datasets saved successfully: train, val, test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ad01e7-346f-455c-b477-2f79dc5d4741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Dataset path\n",
    "data_path = \"KENYA_SIGN_LANGUAGE\"\n",
    "\n",
    "letters = [chr(c) for c in range(ord('A'), ord('Z') + 1)]\n",
    "letter_to_label = {letter: idx for idx, letter in enumerate(letters)}\n",
    "num_classes = 26\n",
    "\n",
    "# Load preprocessed data\n",
    "train_data = np.load(os.path.join(data_path, \"ksl_alphabet_train.npz\"))\n",
    "val_data = np.load(os.path.join(data_path, \"ksl_alphabet_val.npz\"))\n",
    "test_data = np.load(os.path.join(data_path, \"ksl_alphabet_test.npz\"))\n",
    "\n",
    "X_train, y_train = train_data[\"X\"], to_categorical(train_data[\"y\"], num_classes=num_classes)\n",
    "X_val, y_val = val_data[\"X\"], to_categorical(val_data[\"y\"], num_classes=num_classes)\n",
    "X_test, y_test = test_data[\"X\"], to_categorical(test_data[\"y\"], num_classes=num_classes)\n",
    "\n",
    "print(\"Datasets loaded:\")\n",
    "print(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n",
    "\n",
    "# CNN model \n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation=\"relu\", input_shape=(256, 256, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation=\"relu\"),\n",
    "    Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',     # You can also monitor 'val_accuracy'\n",
    "    patience=5,             # Number of epochs with no improvement to wait\n",
    "    restore_best_weights=True,  # Restore model from best epoch\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=60,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping]  # ðŸ‘ˆ Add the callback here\n",
    ")\n",
    "# Evaluate\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"\\nTest Accuracy: {test_acc:.2f}\")\n",
    "\n",
    "# Save model\n",
    "model_path = os.path.join(data_path, \"ksl_alphabet_model.h5\")\n",
    "model.save(model_path)\n",
    "print(f\"Model saved to: {model_path}\")\n",
    "\n",
    "# -------------------------------------------\n",
    "# ðŸ“Š Plot training and validation accuracy/loss\n",
    "# -------------------------------------------\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "plt.title(\"Accuracy Over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title(\"Loss Over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -------------------------------------------\n",
    "# ðŸ“‰ Confusion Matrix\n",
    "# -------------------------------------------\n",
    "# Predict classes on test data\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[chr(i) for i in range(65, 91)])\n",
    "disp.plot(cmap=plt.cm.Blues, xticks_rotation=45)\n",
    "plt.title(\"Confusion Matrix (Test Set)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ffdbb4d-bac8-4fae-a748-5fe80c2d80b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 16:49:32.884132: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749044972.920489   17639 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749044972.931753   17639 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1749044972.960715   17639 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749044972.960746   17639 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749044972.960749   17639 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749044972.960752   17639 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-04 16:49:32.969491: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = 'KENYA_SIGN_LANGUAGE/ksl_alphabet_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmp\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Load trained model (expects 256x256 input)\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mKENYA_SIGN_LANGUAGE/ksl_alphabet_model.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Class labels (A-Z)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m letters \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mchr\u001b[39m(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZ\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/saving/saving_api.py:196\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[1;32m    190\u001b[0m         filepath,\n\u001b[1;32m    191\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[1;32m    193\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[1;32m    194\u001b[0m     )\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_h5_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model_from_hdf5\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    204\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/legacy/saving/legacy_h5_format.py:116\u001b[0m, in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    114\u001b[0m opened_new_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath, h5py\u001b[38;5;241m.\u001b[39mFile)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opened_new_file:\n\u001b[0;32m--> 116\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     f \u001b[38;5;241m=\u001b[39m filepath\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/h5py/_hl/files.py:562\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    553\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    554\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    555\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    556\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    557\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    558\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    559\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    560\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    561\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 562\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/h5py/_hl/files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = 'KENYA_SIGN_LANGUAGE/ksl_alphabet_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "#exec\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import mediapipe as mp\n",
    "\n",
    "# Load trained model (expects 256x256 input)\n",
    "model = tf.keras.models.load_model(\"KENYA_SIGN_LANGUAGE/ksl_alphabet_model.h5\")\n",
    "\n",
    "# Class labels (A-Z)\n",
    "letters = [chr(c) for c in range(ord('A'), ord('Z') + 1)]\n",
    "num_classes = 26\n",
    "\n",
    "# MediaPipe hand setup\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(max_num_hands=1)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Webcam setup\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Cannot access webcam\")\n",
    "    exit()\n",
    "\n",
    "cv2.namedWindow(\"KSL Alphabet Predictor\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"KSL Alphabet Predictor\", 800, 600)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame\")\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(rgb_frame)\n",
    "\n",
    "    h, w, _ = frame.shape\n",
    "    prediction = \"...\"\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            # Calculate bounding box around the hand\n",
    "            x_min, y_min = w, h\n",
    "            x_max = y_max = 0\n",
    "            for lm in hand_landmarks.landmark:\n",
    "                x, y = int(lm.x * w), int(lm.y * h)\n",
    "                x_min = min(x_min, x)\n",
    "                y_min = min(y_min, y)\n",
    "                x_max = max(x_max, x)\n",
    "                y_max = max(y_max, y)\n",
    "\n",
    "            padding = 20\n",
    "            x_min = max(0, x_min - padding)\n",
    "            y_min = max(0, y_min - padding)\n",
    "            x_max = min(w, x_max + padding)\n",
    "            y_max = min(h, y_max + padding)\n",
    "\n",
    "            hand_img = frame[y_min:y_max, x_min:x_max]\n",
    "            if hand_img.size == 0:\n",
    "                continue\n",
    "\n",
    "            # Preprocess hand image: resize to (256,256), normalize\n",
    "            img = cv2.resize(hand_img, (256, 256))\n",
    "            img = img / 255.0\n",
    "            img = np.expand_dims(img, axis=0)\n",
    "\n",
    "            # Predict\n",
    "            pred = model.predict(img)\n",
    "            class_id = np.argmax(pred)\n",
    "            confidence = pred[0][class_id]\n",
    "\n",
    "            prediction = f\"{letters[class_id]} ({confidence*100:.1f}%)\"\n",
    "\n",
    "            # Draw bounding box and label\n",
    "            cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, prediction, (x_min, y_min - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"KSL Alphabet Predictor\", frame)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:  # ESC key to quit\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "hands.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa66dfe-0380-4a18-ad81-95b53f0e9020",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
